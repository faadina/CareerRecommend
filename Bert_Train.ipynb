{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8738985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load dataset\n",
    "career_data = pd.read_csv(\"dataset/datacleanJobstreet.csv\")\n",
    "X = career_data[\"descriptions\"].astype(str)\n",
    "y = career_data[\"job_level_encoded\"]\n",
    "\n",
    "# Load tokenizer and BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "class CareerDataset(Dataset):\n",
    "    def __init__(self, descriptions, tokenizer, max_len=128):\n",
    "        self.descriptions = descriptions\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.descriptions)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        description = str(self.descriptions.iloc[item])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            description,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "def extract_embeddings(dataloader, model, device):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(cls_embeddings.cpu())\n",
    "    return torch.cat(embeddings).numpy()\n",
    "\n",
    "def run_bert_experiment(X, y, train_size, test_size, tokenizer, max_len=128, batch_size=16):\n",
    "    print(f\"\\n=== Train:Test Split -> {int(train_size*100)}:{int(test_size*100)} ===\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=test_size, random_state=42, stratify=y)\n",
    "    print(\"Training:\", Counter(y_train))\n",
    "    print(\"Testing :\", Counter(y_test))\n",
    "\n",
    "    train_dataset = CareerDataset(X_train, tokenizer, max_len)\n",
    "    test_dataset = CareerDataset(X_test, tokenizer, max_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    X_train_embeddings = extract_embeddings(train_loader, bert_model, device)\n",
    "    X_test_embeddings = extract_embeddings(test_loader, bert_model, device)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_embeddings, y_train)\n",
    "    y_pred = clf.predict(X_test_embeddings)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    folder = f\"bert_lr_{int(train_size*100)}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    joblib.dump(clf, f\"{folder}/model.joblib\")\n",
    "    with open(f\"{folder}/report.txt\", \"w\") as f:\n",
    "        f.write(f\"BERT + Logistic Regression ({int(train_size*100)}:{int(test_size*100)})\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(np.array2string(matrix))\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", matrix)\n",
    "\n",
    "def run_bert_sampling(X, y, train_size, test_size, sampler_type, tokenizer, max_len=128, batch_size=16):\n",
    "    label = \"undersample\" if sampler_type == \"under\" else \"oversample\"\n",
    "    sampler = RandomUnderSampler(random_state=42) if sampler_type == \"under\" else RandomOverSampler(random_state=42)\n",
    "\n",
    "    print(f\"\\n=== Train:Test Split -> {int(train_size*100)}:{int(test_size*100)} with {label.capitalize()} ===\")\n",
    "    print(\"Original:\", Counter(y))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=test_size, random_state=42)\n",
    "    print(\"Training:\", Counter(y_train))\n",
    "    print(\"Test    :\", Counter(y_test))\n",
    "\n",
    "    X_train_resampled, y_train_resampled = sampler.fit_resample(X_train.to_frame(), y_train)\n",
    "    X_train_resampled = X_train_resampled[\"descriptions\"]\n",
    "    print(\"AFTER sampling:\", Counter(y_train_resampled))\n",
    "\n",
    "    train_dataset = CareerDataset(X_train_resampled, tokenizer, max_len)\n",
    "    test_dataset = CareerDataset(X_test, tokenizer, max_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    X_train_embeddings = extract_embeddings(train_loader, bert_model, device)\n",
    "    X_test_embeddings = extract_embeddings(test_loader, bert_model, device)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_embeddings, y_train_resampled)\n",
    "    y_pred = clf.predict(X_test_embeddings)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    folder = f\"bert_lr_{label}_{int(train_size*100)}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    joblib.dump(clf, f\"{folder}/model.joblib\")\n",
    "    with open(f\"{folder}/report.txt\", \"w\") as f:\n",
    "        f.write(f\"BERT + Logistic Regression with {label.capitalize()} ({int(train_size*100)}:{int(test_size*100)})\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(np.array2string(matrix))\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6719c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train:Test Split -> 70:30 ===\n",
      "Training: Counter({0: 7681, 1: 6930, 2: 5078})\n",
      "Testing : Counter({0: 3292, 1: 2971, 2: 2176})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1231/1231 [06:14<00:00,  3.28it/s]\n",
      "Extracting embeddings: 100%|██████████| 528/528 [02:07<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5801635264841806\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61      3292\n",
      "           1       0.60      0.64      0.62      2971\n",
      "           2       0.53      0.42      0.47      2176\n",
      "\n",
      "    accuracy                           0.58      8439\n",
      "   macro avg       0.57      0.56      0.57      8439\n",
      "weighted avg       0.58      0.58      0.58      8439\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2075  700  517]\n",
      " [ 771 1900  300]\n",
      " [ 699  556  921]]\n",
      "\n",
      "=== Train:Test Split -> 80:20 ===\n",
      "Training: Counter({0: 8778, 1: 7921, 2: 5803})\n",
      "Testing : Counter({0: 2195, 1: 1980, 2: 1451})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1407/1407 [05:41<00:00,  4.12it/s]\n",
      "Extracting embeddings: 100%|██████████| 352/352 [01:25<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.584962673302524\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62      2195\n",
      "           1       0.60      0.66      0.63      1980\n",
      "           2       0.53      0.40      0.46      1451\n",
      "\n",
      "    accuracy                           0.58      5626\n",
      "   macro avg       0.58      0.57      0.57      5626\n",
      "weighted avg       0.58      0.58      0.58      5626\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1407  471  317]\n",
      " [ 477 1298  205]\n",
      " [ 485  380  586]]\n",
      "\n",
      "=== Train:Test Split -> 90:10 ===\n",
      "Training: Counter({0: 9876, 1: 8911, 2: 6528})\n",
      "Testing : Counter({0: 1097, 1: 990, 2: 726})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1583/1583 [06:22<00:00,  4.14it/s]\n",
      "Extracting embeddings: 100%|██████████| 176/176 [00:42<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5876288659793815\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      1097\n",
      "           1       0.61      0.66      0.63       990\n",
      "           2       0.52      0.39      0.45       726\n",
      "\n",
      "    accuracy                           0.59      2813\n",
      "   macro avg       0.58      0.57      0.57      2813\n",
      "weighted avg       0.58      0.59      0.58      2813\n",
      "\n",
      "Confusion Matrix:\n",
      " [[719 220 158]\n",
      " [232 650 108]\n",
      " [246 196 284]]\n"
     ]
    }
   ],
   "source": [
    "# Run all standard splits\n",
    "for split in [(0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]:\n",
    "    run_bert_experiment(X, y, train_size=split[0], test_size=split[1], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fe029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train:Test Split -> 70:30 with Undersample ===\n",
      "Original: Counter({0: 10973, 1: 9901, 2: 7254})\n",
      "Training: Counter({0: 7639, 1: 6964, 2: 5086})\n",
      "Test    : Counter({0: 3334, 1: 2937, 2: 2168})\n",
      "AFTER sampling: Counter({0: 5086, 1: 5086, 2: 5086})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 954/954 [03:50<00:00,  4.13it/s]\n",
      "Extracting embeddings: 100%|██████████| 528/528 [02:05<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5661808271122171\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58      3334\n",
      "           1       0.61      0.60      0.60      2937\n",
      "           2       0.46      0.56      0.50      2168\n",
      "\n",
      "    accuracy                           0.57      8439\n",
      "   macro avg       0.56      0.57      0.56      8439\n",
      "weighted avg       0.58      0.57      0.57      8439\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1807  652  875]\n",
      " [ 624 1755  558]\n",
      " [ 460  492 1216]]\n",
      "\n",
      "=== Train:Test Split -> 80:20 with Undersample ===\n",
      "Original: Counter({0: 10973, 1: 9901, 2: 7254})\n",
      "Training: Counter({0: 8765, 1: 7907, 2: 5830})\n",
      "Test    : Counter({0: 2208, 1: 1994, 2: 1424})\n",
      "AFTER sampling: Counter({0: 5830, 1: 5830, 2: 5830})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1094/1094 [04:20<00:00,  4.19it/s]\n",
      "Extracting embeddings: 100%|██████████| 352/352 [01:22<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5769640952719517\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59      2208\n",
      "           1       0.62      0.62      0.62      1994\n",
      "           2       0.47      0.56      0.51      1424\n",
      "\n",
      "    accuracy                           0.58      5626\n",
      "   macro avg       0.57      0.58      0.57      5626\n",
      "weighted avg       0.58      0.58      0.58      5626\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1220  446  542]\n",
      " [ 400 1233  361]\n",
      " [ 324  307  793]]\n",
      "\n",
      "=== Train:Test Split -> 90:10 with Undersample ===\n",
      "Original: Counter({0: 10973, 1: 9901, 2: 7254})\n",
      "Training: Counter({0: 9879, 1: 8901, 2: 6535})\n",
      "Test    : Counter({0: 1094, 1: 1000, 2: 719})\n",
      "AFTER sampling: Counter({0: 6535, 1: 6535, 2: 6535})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1226/1226 [04:48<00:00,  4.25it/s]\n",
      "Extracting embeddings: 100%|██████████| 176/176 [00:41<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.57518663348738\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60      1094\n",
      "           1       0.62      0.61      0.61      1000\n",
      "           2       0.46      0.54      0.50       719\n",
      "\n",
      "    accuracy                           0.58      2813\n",
      "   macro avg       0.57      0.57      0.57      2813\n",
      "weighted avg       0.58      0.58      0.58      2813\n",
      "\n",
      "Confusion Matrix:\n",
      " [[623 220 251]\n",
      " [188 608 204]\n",
      " [173 159 387]]\n"
     ]
    }
   ],
   "source": [
    "# Run all undersampling splits\n",
    "for split in [(0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]:\n",
    "    run_bert_sampling(X, y, train_size=split[0], test_size=split[1], sampler_type=\"under\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c520b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train:Test Split -> 70:30 with Oversample ===\n",
      "Original: Counter({0: 10973, 1: 9901, 2: 7254})\n",
      "Training: Counter({0: 7639, 1: 6964, 2: 5086})\n",
      "Test    : Counter({0: 3334, 1: 2937, 2: 2168})\n",
      "AFTER sampling: Counter({0: 7639, 2: 7639, 1: 7639})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1433/1433 [05:37<00:00,  4.24it/s]\n",
      "Extracting embeddings: 100%|██████████| 528/528 [02:03<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5708022277521033\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59      3334\n",
      "           1       0.61      0.61      0.61      2937\n",
      "           2       0.47      0.54      0.50      2168\n",
      "\n",
      "    accuracy                           0.57      8439\n",
      "   macro avg       0.57      0.57      0.57      8439\n",
      "weighted avg       0.58      0.57      0.57      8439\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1847  666  821]\n",
      " [ 619 1789  529]\n",
      " [ 488  499 1181]]\n",
      "\n",
      "=== Train:Test Split -> 80:20 with Oversample ===\n",
      "Original: Counter({0: 10973, 1: 9901, 2: 7254})\n",
      "Training: Counter({0: 8765, 1: 7907, 2: 5830})\n",
      "Test    : Counter({0: 2208, 1: 1994, 2: 1424})\n",
      "AFTER sampling: Counter({0: 8765, 1: 8765, 2: 8765})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1644/1644 [06:26<00:00,  4.26it/s]\n",
      "Extracting embeddings: 100%|██████████| 352/352 [01:22<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5721649484536082\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.59      2208\n",
      "           1       0.62      0.62      0.62      1994\n",
      "           2       0.46      0.54      0.50      1424\n",
      "\n",
      "    accuracy                           0.57      5626\n",
      "   macro avg       0.57      0.57      0.57      5626\n",
      "weighted avg       0.58      0.57      0.57      5626\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1222  451  535]\n",
      " [ 406 1232  356]\n",
      " [ 340  319  765]]\n",
      "\n",
      "=== Train:Test Split -> 90:10 with Oversample ===\n",
      "Original: Counter({0: 10973, 1: 9901, 2: 7254})\n",
      "Training: Counter({0: 9879, 1: 8901, 2: 6535})\n",
      "Test    : Counter({0: 1094, 1: 1000, 2: 719})\n",
      "AFTER sampling: Counter({0: 9879, 1: 9879, 2: 9879})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1853/1853 [07:16<00:00,  4.25it/s]\n",
      "Extracting embeddings: 100%|██████████| 176/176 [00:40<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5862068965517241\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60      1094\n",
      "           1       0.63      0.63      0.63      1000\n",
      "           2       0.48      0.55      0.51       719\n",
      "\n",
      "    accuracy                           0.59      2813\n",
      "   macro avg       0.58      0.58      0.58      2813\n",
      "weighted avg       0.59      0.59      0.59      2813\n",
      "\n",
      "Confusion Matrix:\n",
      " [[625 222 247]\n",
      " [189 628 183]\n",
      " [169 154 396]]\n"
     ]
    }
   ],
   "source": [
    "# Run all oversampling splits\n",
    "for split in [(0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]:\n",
    "    run_bert_sampling(X, y, train_size=split[0], test_size=split[1], sampler_type=\"over\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e151f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split           Type            Accuracy  \n",
      "========================================\n",
      "70/30           Standard        0.5802    \n",
      "70/30           Undersampling   0.5662    \n",
      "70/30           Oversampling    0.5708    \n",
      "80/20           Standard        0.5850    \n",
      "80/20           Undersampling   0.5770    \n",
      "80/20           Oversampling    0.5722    \n",
      "90/10           Standard        0.5876    \n",
      "90/10           Undersampling   0.5752    \n",
      "90/10           Oversampling    0.5862    \n",
      "\n",
      "✅ Summary saved to bert_accuracy_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def extract_accuracy(report_path):\n",
    "    if not os.path.exists(report_path):\n",
    "        return None\n",
    "    with open(report_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    match = re.search(r\"Accuracy:\\s+([\\d.]+)\", content)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# Define all result folders\n",
    "splits = [70, 80, 90]\n",
    "types = [\"\", \"undersample_\", \"oversample_\"]\n",
    "labels = {\"\": \"Standard\", \"undersample_\": \"Undersampling\", \"oversample_\": \"Oversampling\"}\n",
    "\n",
    "results = []\n",
    "\n",
    "for split in splits:\n",
    "    for t in types:\n",
    "        folder = f\"bert_lr_{t}{split}\"\n",
    "        report_path = os.path.join(folder, \"report.txt\")\n",
    "        accuracy = extract_accuracy(report_path)\n",
    "        acc_str = f\"{accuracy:.4f}\" if accuracy else \"N/A\"\n",
    "        results.append([f\"{split}/{100-split}\", labels[t], acc_str])\n",
    "\n",
    "# Print table\n",
    "print(f\"{'Split':<15} {'Type':<15} {'Accuracy':<10}\")\n",
    "print(\"=\"*40)\n",
    "for row in results:\n",
    "    print(f\"{row[0]:<15} {row[1]:<15} {row[2]:<10}\")\n",
    "\n",
    "# Save to CSV\n",
    "with open(\"bert_accuracy_summary.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Split\", \"Type\", \"Accuracy\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"\\n✅ Summary saved to bert_accuracy_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
